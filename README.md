# ğŸ§¬ FairSurvTrans: Fairness-Aware Transformer for Survival Prediction in HCT

**LLM-inspired transformer model for equitable survival prediction across racial groups in allogeneic hematopoietic cell transplantation (HCT)**

---

## ğŸ“Œ Overview

**FairSurvTrans** is a transformer-based deep learning model designed for structured clinical data to predict patient survival after HCT while minimizing racial bias. Inspired by LLMs like BERT/GPT, it applies multi-head self-attention and a fairness-sensitive loss function to achieve both high accuracy and equitable subgroup performance.

Developed using a racially balanced synthetic dataset (from the Kaggle FairSurvival Challenge), it integrates dynamic group weighting and stratified C-index evaluation.

---

## ğŸ¯ Key Features

- ğŸ” End-to-end transformer for survival prediction
- âš–ï¸ Fairness-aware loss: Cox loss + stratified fairness penalty
- ğŸ§ª Subgroup C-index & calibration monitoring
- ğŸ“Š C-index: **0.6738 Â± 0.0031**, Fairness Penalty: **0.0002 Â± 0.0001**
- âœ… Consistent performance across 6 racial groups

---

## ğŸ“‚ Project Structure

```
FairSurvTrans/
â”œâ”€â”€ data/                            # Synthetic dataset (processed or raw)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ FairSurvTrans_Model.ipynb    # Complete training + evaluation pipeline
â”œâ”€â”€ requirements.txt                 # Environment dependencies
â””â”€â”€ README.md                        # Project documentation
```


---

## ğŸ› ï¸ Methodology Summary

### âš™ï¸ Architecture

- Mixed-type embedding for categorical & numerical features
- Learnable positional encoding (non-sequential tabular data)
- Multi-head self-attention + residuals + GELU
- Feature attention pooling for patient-level aggregation
- Risk prediction via MLP head

### ğŸ“ˆ Loss Function

Final objective:
```
L_fair = L_cox + Î» Â· FairnessPenalty
```
Where:
- `L_cox` = Negative partial log-likelihood from Cox model  
- `FairnessPenalty` = Mean squared deviation in C-index across subgroups  
- `Î»` = fairness penalty weight (default: 0.2)

### âš–ï¸ Dynamic Group Weighting
Poorer-performing subgroups receive higher weight during training:
```python
w_r = clip(1.0 + Î± * (C_avg - C_r), 0.5, 2.0)
```

---

## ğŸ“Š Evaluation Highlights

| Model           | C-Index         | Fairness Penalty |
|----------------|------------------|------------------|
| **FairSurvTrans** | **0.6738 Â± 0.0031** | **0.0002 Â± 0.0001** |
| CoxPH           | 0.6348 Â± 0.0057 | 0.0816           |
| DeepSurv        | 0.6219 Â± 0.0045 | 0.0724           |
| XGBoost-AFT     | 0.3285 Â± 0.0051 | 0.0728           |

âœ… Statistically significant improvements (p < 0.05)  
âœ… Best subgroup consistency  
âœ… Accurate 1-year survival risk calibration

---

## ğŸ“ˆ Ablation Study (Component Contribution)

| Configuration         | C-Index     | Fairness Penalty |
|----------------------|-------------|------------------|
| Full Model           | 0.6738      | 0.0002           |
| No Fairness Loss     | 0.6737      | 0.0000           |
| No Dynamic Weights   | 0.6738      | 0.0002           |
| No Fair Components   | 0.6737      | 0.0000           |

> Fairness improves subgroup equity **without** degrading global performance.

---

## ğŸ§  Future Work

- âœ… Validate on real-world registries (CIBMTR, SEER)
- ğŸ”„ Add longitudinal modeling (e.g., TransformerJM-style)
- ğŸ§¬ Extend with ClinicalBERT for multimodal inputs
- ğŸ‘¥ Human-in-the-loop fairness auditing

---

## ğŸ‘¨â€ğŸ’» Authors

- **Siddhi Patil** â€“ [siddhipatil064@gmail.com](mailto:siddhipatil064@gmail.com)  
- **Vijay Kalmani** â€“ [vijaykalmani@gmail.com](mailto:vijaykalmani@gmail.com) *(Corresponding Author)*  
- **Amol Adamuthe** â€“ [amol.admuthe@gmail.com](mailto:amol.admuthe@gmail.com)

---

## ğŸ“„ Citation

```bibtex
@article{fairsurvtrans2025,
  title     = {FairSurvTrans: An LLM-Inspired Transformer for Equitable Survival Prediction in Hematopoietic Cell Transplantation},
  author    = {Kalmani, Vijay and Patil, Siddhi and Adamuthe, Amol},
  journal   = {Under Review},
  year      = {2025}
}
```

---

## ğŸ“œ License

This project is released under an academic-use license. Contact authors for commercial use.

---

> _"AI in healthcare must ensure fairness, transparency, and equitable treatment across all patient groups."_
